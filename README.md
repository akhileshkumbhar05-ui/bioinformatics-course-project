# Tumor–Normal Differential Expression, Pathways, and ML Classifier (TCGA-BRCA)

TCGA-BRCA RNA-seq analysis pipeline for the **Bioinformatics** course project.

The goal of this project is to:

1. Download gene-level RNA-seq counts for **TCGA-BRCA** from the NCI Genomic Data Commons (GDC).
2. Build a clean **gene × sample count matrix** plus a **sample metadata table**.
3. (Next steps) Perform tumor vs normal **differential expression**, **pathway analysis (GSEA/ssGSEA)**, and build a simple **machine-learning classifier** that distinguishes tumor from normal samples.

This repository currently contains the **data acquisition and matrix construction** part of the pipeline. Downstream analysis notebooks will be added as the course project progresses.

---

## Repository structure

- `Bioinformatics_Course_Project.ipynb`  
  Main notebook. Queries the GDC API for TCGA-BRCA STAR counts, downloads files in chunks, and builds:
  - `tcga_brca_star_metadata.csv` (sample metadata)
  - `tcga_brca_star_counts_matrix.csv` (gene × sample raw counts)

- `LICENSE`  
  MIT license.

- `.gitignore`  
  Ignore rules for Python and Jupyter files.

- `ai_usage.md`  
  Notes on how AI tools (ChatGPT) were used and how outputs were checked.

More notebooks will be added later for DESeq2/PyDESeq2, GSEA/ssGSEA, and machine-learning.

---

## Data

- **Source:** NCI Genomic Data Commons (GDC) – [TCGA-BRCA project](https://portal.gdc.cancer.gov/projects/TCGA-BRCA)  
- **Program / Project:** TCGA / TCGA-BRCA  
- **Data category:** Transcriptome Profiling  
- **Data type:** Gene Expression Quantification  
- **Workflow type:** STAR – Counts  
- **Access:** Only **open-access** data are used.

The notebook filters samples to:

- `Primary Tumor`
- `Solid Tissue Normal`

For prototyping in Google Colab, the notebook currently uses a subset of **up to 80 samples** (controlled by `MAX_FILES`). The final project may use a larger cohort depending on available memory.

Outputs generated by the notebook:

- `tcga_brca_star_metadata.csv`  
  - One row per sample.  
  - Example columns: `file_id`, `file_name`, `case_id`, `case_submitter_id`, `sample_submitter_id`, `sample_type`, `project_id`, `gender`, `age_at_diagnosis`.

- `tcga_brca_star_counts_matrix.csv`  
  - Rows = Ensembl gene IDs (version stripped).  
  - Columns = TCGA sample submitter IDs.  
  - Values = unstranded STAR gene-level counts (non-gene summary rows removed).

---

## Methods (current implementation)

All current code lives in `Bioinformatics_Course_Project.ipynb` and is written in Python 3 (tested in Google Colab).

High-level steps:

1. **Configure filters**  
   - Set `PROJECT_ID = "TCGA-BRCA"`.  
   - Restrict to the transcriptome profiling / STAR – Counts workflow.  
   - Keep only `Primary Tumor` and `Solid Tissue Normal` sample types.

2. **Query GDC Files API**  
   - Use the `/files` endpoint with a JSON filter.  
   - Expand `cases.samples` and `cases.demographic` to pull sample type, gender, age, etc.  
   - Build a `pandas` DataFrame with relevant fields.

3. **Build metadata table**  
   - Keep only the sample types of interest.  
   - Optionally down-sample to at most `MAX_FILES` samples for Colab memory limits.  
   - Save as `tcga_brca_star_metadata.csv`.

4. **Download STAR counts in chunks**  
   - Use the GDC `/data` endpoint with POST requests, batching 20 file IDs at a time.  
   - Stream each `.tar.gz` to disk, extract TSVs into `gdc_tcga_brca_star/`, then delete the archive.

5. **Parse STAR counts and build matrix**  
   - Function `read_star_counts_file(path)` handles:
     - GDC `gene_counts.tsv` format with `gene_id` / `unstranded` columns.
     - STAR `ReadsPerGene.out.tab` format (4 columns; skip first 4 summary rows).
   - Remove summary rows (`N_unmapped`, etc.), strip Ensembl version suffixes, and return a `Series` of counts indexed by `gene_id`.
   - Function `build_counts_matrix(meta, DOWNLOAD_DIR)`:
     - Reads each file **one at a time** into memory.  
     - Collects per-sample Series in a list.  
     - Uses a single `pd.concat` to produce the full gene × sample matrix.  
     - Fills missing values with zero and casts to `int`.  
     - Optionally drops pseudo-genes containing `"PAR_Y"`.

The notebook prints basic shapes and summaries to verify that the counts and metadata line up.

---

## Planned downstream analysis (not yet implemented)

Additional notebooks will be added for:

1. **Differential Expression (DE)**  
   - Use [DESeq2 / PyDESeq2](https://biocontainers.pro/tools/deseq2) with design `~ condition` (Tumor vs Normal).  
   - Generate MA plots, volcano plots, and a ranked table of genes.

2. **Pathway Analysis**  
   - Run GSEA with MSigDB Hallmark gene sets.  
   - Optionally compute single-sample GSEA (ssGSEA / GSVA) scores for pathways.

3. **Machine-learning Classifier**  
   - Build an interpretable Tumor vs Normal classifier (logistic regression ± random forest) using scikit-learn.  
   - Evaluate with stratified cross-validation (ROC-AUC, PR-AUC, accuracy, F1).

---

## How to run (Google Colab)

1. Open the notebook from GitHub in Colab  
   - In GitHub, open `Bioinformatics_Course_Project.ipynb`.  
   - Click **“Open in Colab”** (if available) or copy the GitHub URL into Colab’s *File → Open Notebook → GitHub* tab.

2. Run all cells  
   - Runtime → “Run all”.  
   - The notebook will:
     - Query the GDC API.  
     - Create `tcga_brca_star_metadata.csv`.  
     - Download STAR count files (this can take a while).  
     - Build and save `tcga_brca_star_counts_matrix.csv`.

3. Check outputs  
   - Confirm shapes (printed in the notebook).  
   - Download the two CSVs if you want to use them in other notebooks.

> Note: only open-access TCGA-BRCA data are used; you do **not** need dbGaP authorization for this pipeline.

---

## Reproducibility and AI usage

- All major steps (query, download, parsing, matrix build) are scripted and can be re-run from a clean Colab runtime.  
- A `requirements.txt` or `environment.yml` file will be added later to pin package versions.  
- `ai_usage.md` documents how ChatGPT was used to help design and debug the code and to edit project documentation. All AI-generated code and text are manually reviewed and tested before being committed.

---

## License

This project is released under the **MIT License** (see `LICENSE`).
